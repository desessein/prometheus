{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45ba767-ba7e-4adf-a00a-66d58efa4630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0.post1)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (69.0.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras numpy matplotlib pandas scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0ad3d7-e152-4c48-acae-6ca36ef57be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 19:19:56.810290: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-01 19:19:56.810337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-01 19:19:56.811662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-01 19:19:56.819067: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-01 19:19:57.659436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e38ece-556a-41e4-bfcb-dddbd6f5ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import *\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39706bf-76ac-448e-b006-e4a676507c0b",
   "metadata": {},
   "source": [
    "### Defining the train images path and partial test images path in which we have to add the image to convert it into full path.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f110c020-f4c0-4aa6-b5a3-6ef608b8087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'DataSet/Train'\n",
    "test_path = 'DataSet\\Test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d700833-11a3-4329-9651-0f6cc16b104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator().flow_from_directory(train_path,target_size = (224,224),classes=['RG_Frente','RG_Verso', 'CPF_Frente', 'CPF_Verso', 'CNH_Frente', 'CNH_Verso'],batch_size = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ef01b5-480f-4684-bf46-079155c9a697",
   "metadata": {},
   "source": [
    "### Importing keras pretrained model (without top layers) resnet50 which we are going to use as base model.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc8418e7-5a1a-43e0-b582-3288d9aa3aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 19:20:13.936095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18455 MB memory:  -> device: 0, name: NVIDIA RTX A4500, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.resnet50.ResNet50( weights = 'imagenet',include_top = False,input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be906d6-f73e-460e-adea-19ae1a0c63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cc054-6ae8-4b98-a811-c42ecf03a7cc",
   "metadata": {},
   "source": [
    "### Making keras sequential model by using base model layer as its lower layer and two fully connected dense layer as its top layer which are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b48367-802c-4996-86d9-dc63ad2fdfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 602118    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24189830 (92.28 MB)\n",
      "Trainable params: 602118 (2.30 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(1000,activation = 'relu'))\n",
    "model.add(Dense(6,activation = 'sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d27822-76b6-4165-8300-ff8ab84aa98c",
   "metadata": {},
   "source": [
    "### Compile and train the model on epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a36fca6-04fe-4755-ae17-ee8359d89c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbcbc5f6-ef78-4cf0-9cd4-0dcfc9df7911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 49ms/step - loss: 1.8260 - accuracy: 0.5306\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.3643 - accuracy: 0.9184\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.0798 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.1777 - accuracy: 0.9388\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 7.2064e-06 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 1s 70ms/step - loss: 0.0517 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 1s 70ms/step - loss: 4.6703e-07 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 4.7707e-06 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 1s 69ms/step - loss: 0.0449 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 1s 68ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 63ms/step - loss: 9.7151e-06 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 6.1732e-07 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 1.1189e-08 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 8.5613e-07 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 1s 67ms/step - loss: 3.6636e-07 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 1.4728e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batches,\n",
    "                              epochs=20,\n",
    "                              steps_per_epoch = 7,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f754bfb-ef6b-400b-a7d5-3f4232945590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lunar keras saved\n"
     ]
    }
   ],
   "source": [
    "model.save('lunar-v7.h5')\n",
    "print(\"lunar keras saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db9481c2-3f55-462d-a3a7-579a8200544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 6)\n",
      "[-1063.0544   -988.35547  -542.79407  -117.1619   -564.07336  -314.77563]\n"
     ]
    }
   ],
   "source": [
    "def predict(img_path):\n",
    "    test_image = image.load_img(img_path, target_size=(224, 224))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = model.predict(test_image, batch_size=1)\n",
    "\n",
    "    print(type(result)) \n",
    "    print(result.shape)\n",
    "\n",
    "    return result\n",
    "    # # # Softmax\n",
    "    # # # Apply Softmax \n",
    "    # probabilities = softmax(result[0])\n",
    "\n",
    "    # # # Find the most likely class\n",
    "    # predicted_class = np.argmax(probabilities)\n",
    "      \n",
    "    # # # Mapping classes to labels (add your labels here)\n",
    "    # class_labels = [\"RG Frente\", \"RG Verso\", \"CPF Frente\", \"CPF Verso\", \"CNH Frente\", \"CNH Verso\"]\n",
    "    \n",
    "    # # # Print results  \n",
    "    # print(f\"Predicted Class: {class_labels[predicted_class]}, Probabilities: {probabilities}\") \n",
    "    \n",
    "    # # # Remove the hardcoded if/else logic \n",
    "    # return class_labels[predicted_class] \n",
    "\n",
    "label = predict('DataSet/Predict/rf1.jpg')\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "195480b5-7ee1-4f7a-9a94-a34410a54f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.layers' has no attribute 'activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m softmax_layers \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivations\u001b[49m\u001b[38;5;241m.\u001b[39mSoftmax()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m])\n\u001b[1;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m softmax_layers(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.layers' has no attribute 'activations'"
     ]
    }
   ],
   "source": [
    "softmax_layers = keras.layers.activations.Softmax()\n",
    "\n",
    "input = np.array([1.0, 2.0, 1.0])\n",
    "\n",
    "result = softmax_layers(input)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "881b8b93-a0df-4cd2-afe2-ecc364317123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_and_predict_jpgs(directory_path):\n",
    "  for filename in os.listdir(directory_path):\n",
    "      if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "          img_path = os.path.join(directory_path, filename)\n",
    "          prediction = predict(img_path)\n",
    "          print(f\"Image: {filename} - Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95c255ea-d223-44a1-bdaa-3b25b6e60b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 6)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDataSet/Predict/rf1.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(label)\n",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# # Softmax\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# # Apply Softmax \u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # Find the most likely class\u001b[39;00m\n\u001b[1;32m     14\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(probabilities)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/activations.py:87\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.activations.softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Softmax converts a vector of values to a probability distribution.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    The elements of the output vector are in range (0, 1) and sum to 1.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    ...                               activation=tf.keras.activations.softmax)\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5442\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(x, axis)\u001b[0m\n\u001b[1;32m   5428\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.backend.softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5429\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   5430\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_generate_docs\n\u001b[1;32m   5431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   5432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Softmax of a tensor.\u001b[39;00m\n\u001b[1;32m   5433\u001b[0m \n\u001b[1;32m   5434\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5440\u001b[0m \u001b[38;5;124;03m        A tensor.\u001b[39;00m\n\u001b[1;32m   5441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   5443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot apply softmax to a tensor that is 1D. Received input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5445\u001b[0m         )\n\u001b[1;32m   5447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(axis, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "label = predict('DataSet/Predict/rf1.jpg')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6332a175-3e4c-4dff-9808-3e1142427f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "[[3.7555170e-32 1.0000000e+00 4.8909164e-37 0.0000000e+00 2.3450348e-27\n",
      "  0.0000000e+00]]\n",
      "[3.7555170e-32 1.0000000e+00 4.8909164e-37 0.0000000e+00 2.3450348e-27\n",
      " 0.0000000e+00]\n",
      "1.0\n",
      "RG Verso\n"
     ]
    }
   ],
   "source": [
    "label = predict('DataSet/Predict/rv1.jpg')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd9f5941-b8eb-4c94-8768-fdfb1df9b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso1.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 2.4562238e-21 1.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 2.4562238e-21 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "0.0\n",
      "Image: cpf_verso0.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso5.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso7.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso6.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso4.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso8.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso2.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 1. 0. 0.]]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_verso3.jpg - Prediction: CPF Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1583165e-28\n",
      "  0.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1583165e-28\n",
      " 0.0000000e+00]\n",
      "0.0\n",
      "Image: cpf_Frente6.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente1.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente8.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente7.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente5.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente4.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente2.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente0.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 1. 0. 0. 0.]]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "0.0\n",
      "Image: cpf_Frente3.jpg - Prediction: CPF Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.000000e+00 0.000000e+00 2.349102e-25 0.000000e+00 4.746988e-30\n",
      "  1.000000e+00]]\n",
      "[0.000000e+00 0.000000e+00 2.349102e-25 0.000000e+00 4.746988e-30\n",
      " 1.000000e+00]\n",
      "0.0\n",
      "Image: cnh_verso5.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.000000e+00 0.000000e+00 2.052419e-26 0.000000e+00 5.675011e-15\n",
      "  1.000000e+00]]\n",
      "[0.000000e+00 0.000000e+00 2.052419e-26 0.000000e+00 5.675011e-15\n",
      " 1.000000e+00]\n",
      "0.0\n",
      "Image: cnh_verso6.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 7.9190153e-12 0.0000000e+00 6.6198288e-03\n",
      "  1.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 7.9190153e-12 0.0000000e+00 6.6198288e-03\n",
      " 1.0000000e+00]\n",
      "0.0\n",
      "Image: cnh_verso8.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 1.7975405e-35 0.0000000e+00 1.3619528e-27\n",
      "  1.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 1.7975405e-35 0.0000000e+00 1.3619528e-27\n",
      " 1.0000000e+00]\n",
      "0.0\n",
      "Image: cnh_verso7.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 1.5766125e-26 0.0000000e+00 0.0000000e+00\n",
      "  9.9983144e-01]]\n",
      "[0.0000000e+00 0.0000000e+00 1.5766125e-26 0.0000000e+00 0.0000000e+00\n",
      " 9.9983144e-01]\n",
      "0.0\n",
      "Image: cnh_verso3.jpg - Prediction: None\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.000000e+00 0.000000e+00 9.299502e-31 0.000000e+00 0.000000e+00\n",
      "  1.000000e+00]]\n",
      "[0.000000e+00 0.000000e+00 9.299502e-31 0.000000e+00 0.000000e+00\n",
      " 1.000000e+00]\n",
      "0.0\n",
      "Image: cnh_verso2.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.0000000e+00 9.0665824e-34 4.2469243e-20 0.0000000e+00 2.3879665e-36\n",
      "  1.0000000e+00]]\n",
      "[0.0000000e+00 9.0665824e-34 4.2469243e-20 0.0000000e+00 2.3879665e-36\n",
      " 1.0000000e+00]\n",
      "9.066582e-34\n",
      "Image: cnh_verso1.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 9.9791428e-26 0.0000000e+00 2.5077979e-26\n",
      "  1.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 9.9791428e-26 0.0000000e+00 2.5077979e-26\n",
      " 1.0000000e+00]\n",
      "0.0\n",
      "Image: cnh_verso4.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.0000000e+00 2.4572387e-34 3.4941922e-23 0.0000000e+00 6.9609320e-26\n",
      "  1.0000000e+00]]\n",
      "[0.0000000e+00 2.4572387e-34 3.4941922e-23 0.0000000e+00 6.9609320e-26\n",
      " 1.0000000e+00]\n",
      "2.4572387e-34\n",
      "Image: cnh_verso0.jpg - Prediction: CNH Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 1.1643221e-35 0.0000000e+00 1.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 1.1643221e-35 0.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00]\n",
      "0.0\n",
      "Image: cnh_front5.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0. 0. 0. 0. 1. 0.]]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "0.0\n",
      "Image: cnh_front4.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[0.0000000e+00 0.0000000e+00 1.4107112e-21 0.0000000e+00 1.0000000e+00\n",
      "  0.0000000e+00]]\n",
      "[0.0000000e+00 0.0000000e+00 1.4107112e-21 0.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00]\n",
      "0.0\n",
      "Image: cnh_front7.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[0. 0. 0. 0. 1. 0.]]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "0.0\n",
      "Image: cnh_front1.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00\n",
      "  8.006894e-38]]\n",
      "[0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.000000e+00\n",
      " 8.006894e-38]\n",
      "0.0\n",
      "Image: cnh_front2.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 0. 1. 0.]]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "0.0\n",
      "Image: cnh_front0.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 0. 1. 0.]]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "0.0\n",
      "Image: cnh_front8.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0.000000e+00 0.000000e+00 4.236175e-15 0.000000e+00 1.000000e+00\n",
      "  0.000000e+00]]\n",
      "[0.000000e+00 0.000000e+00 4.236175e-15 0.000000e+00 1.000000e+00\n",
      " 0.000000e+00]\n",
      "0.0\n",
      "Image: cnh_front6.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0. 0. 0. 0. 1. 0.]]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "0.0\n",
      "Image: cnh_front3.jpg - Prediction: CNH Frente\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[1. 0. 0. 0. 0. 0.]]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "Image: rf3.jpg - Prediction: RG Frente\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1. 0. 0. 0. 0. 0.]]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "Image: rf2.jpg - Prediction: RG Frente\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8427925e-23\n",
      "  0.0000000e+00]]\n",
      "[1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8427925e-23\n",
      " 0.0000000e+00]\n",
      "0.0\n",
      "Image: rf4.jpg - Prediction: RG Frente\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 3.1663677e-28 0.0000000e+00 2.9264163e-18\n",
      "  5.1713064e-34]]\n",
      "[0.0000000e+00 1.0000000e+00 3.1663677e-28 0.0000000e+00 2.9264163e-18\n",
      " 5.1713064e-34]\n",
      "1.0\n",
      "Image: rv2.jpg - Prediction: RG Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[0.0000000e+00 1.0000000e+00 5.7571072e-37 0.0000000e+00 1.6285304e-16\n",
      "  0.0000000e+00]]\n",
      "[0.0000000e+00 1.0000000e+00 5.7571072e-37 0.0000000e+00 1.6285304e-16\n",
      " 0.0000000e+00]\n",
      "1.0\n",
      "Image: rv3.jpg - Prediction: RG Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[7.1755152e-26 1.0000000e+00 1.0914486e-04 0.0000000e+00 1.4310670e-17\n",
      "  7.8372854e-35]]\n",
      "[7.1755152e-26 1.0000000e+00 1.0914486e-04 0.0000000e+00 1.4310670e-17\n",
      " 7.8372854e-35]\n",
      "1.0\n",
      "Image: rv4.jpg - Prediction: RG Verso\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[1. 0. 0. 0. 0. 0.]]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "0.0\n",
      "Image: rf1.jpg - Prediction: RG Frente\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[3.7555170e-32 1.0000000e+00 4.8909164e-37 0.0000000e+00 2.3450348e-27\n",
      "  0.0000000e+00]]\n",
      "[3.7555170e-32 1.0000000e+00 4.8909164e-37 0.0000000e+00 2.3450348e-27\n",
      " 0.0000000e+00]\n",
      "1.0\n",
      "Image: rv1.jpg - Prediction: RG Verso\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'DataSet/Predict'\n",
    "get_and_predict_jpgs(directory_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
